# PostgreSQL vs MySQL for ReadPilot

## å®é™…ä»£ç å¯¹æ¯”

### åœºæ™¯ 1: å­˜å‚¨å’ŒæŸ¥è¯¢æ–‡æ¡£æ‘˜è¦

#### PostgreSQL (æ¨è) âœ…
```python
# models/document.py
class Document(Base):
    __tablename__ = "documents"

    id = Column(String, primary_key=True)
    summary = Column(JSONB)  # åŸç”Ÿ JSONB æ”¯æŒ

# æŸ¥è¯¢ç¤ºä¾‹
session.query(Document).filter(
    Document.summary['type'].astext == 'technical',
    Document.summary['key_insights'].contains(['AI'])
).all()

# SQL æŸ¥è¯¢
"""
SELECT * FROM documents
WHERE summary->>'type' = 'technical'
AND summary->'key_insights' @> '["AI"]'::jsonb;
"""
```

#### MySQL (ä¸æ¨è) âš ï¸
```python
# models/document.py
class Document(Base):
    __tablename__ = "documents"

    id = Column(String, primary_key=True)
    summary = Column(JSON)  # JSON ç±»å‹ï¼Œä½†æŸ¥è¯¢æ…¢

# æŸ¥è¯¢ç¤ºä¾‹ - å¤æ‚ä¸”æ…¢
from sqlalchemy import func
session.query(Document).filter(
    func.json_extract(Document.summary, '$.type') == 'technical'
).all()

# SQL æŸ¥è¯¢ - è¯­æ³•å¤æ‚
"""
SELECT * FROM documents
WHERE JSON_EXTRACT(summary, '$.type') = 'technical'
AND JSON_CONTAINS(
    JSON_EXTRACT(summary, '$.key_insights'),
    '["AI"]'
);
"""
```

---

### åœºæ™¯ 2: å‘é‡æœç´¢ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰

#### PostgreSQL + pgvector (æ¨è) âœ…âœ…âœ…
```python
# models/document.py
from pgvector.sqlalchemy import Vector

class DocumentChunk(Base):
    __tablename__ = "document_chunks"

    id = Column(String, primary_key=True)
    text = Column(Text)
    embedding = Column(Vector(1536))  # OpenAI embeddings

# å‘é‡æœç´¢ - åŸç”Ÿæ”¯æŒ
from pgvector.sqlalchemy import cosine_distance

query_embedding = [0.1, 0.2, ...]  # 1536ç»´å‘é‡

results = session.query(
    DocumentChunk,
    (1 - cosine_distance(DocumentChunk.embedding, query_embedding)).label('similarity')
).order_by(
    cosine_distance(DocumentChunk.embedding, query_embedding)
).limit(10).all()

# SQL - ç®€æ´é«˜æ•ˆ
"""
SELECT *, 1 - (embedding <=> '[0.1,0.2,...]') as similarity
FROM document_chunks
ORDER BY embedding <=> '[0.1,0.2,...]'
LIMIT 10;
"""
```

#### MySQL (ä¸å¯ç”¨) âŒ
```python
# models/document.py
class DocumentChunk(Base):
    __tablename__ = "document_chunks"

    id = Column(String, primary_key=True)
    text = Column(Text)
    embedding_json = Column(JSON)  # ğŸ˜¢ åªèƒ½å­˜ JSON

# å‘é‡æœç´¢ - å¿…é¡»åœ¨åº”ç”¨å±‚å®ç°
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# 1. ä»æ•°æ®åº“å–å‡ºæ‰€æœ‰æ•°æ®ï¼ˆæ€§èƒ½æå·®ï¼ï¼‰
all_chunks = session.query(DocumentChunk).all()

# 2. åœ¨å†…å­˜ä¸­è®¡ç®—
query_embedding = np.array([0.1, 0.2, ...])
embeddings = np.array([json.loads(c.embedding_json) for c in all_chunks])

# 3. è®¡ç®—ç›¸ä¼¼åº¦
similarities = cosine_similarity([query_embedding], embeddings)[0]

# 4. æ’åºè¿”å›
top_indices = np.argsort(similarities)[::-1][:10]
results = [all_chunks[i] for i in top_indices]

# âš ï¸ é—®é¢˜ï¼š
# - å¿…é¡»åŠ è½½æ‰€æœ‰æ•°æ®åˆ°å†…å­˜
# - 10ä¸‡æ¡æ•°æ® = 10ä¸‡ * 1536 * 4 bytes â‰ˆ 600MB+
# - æ— æ³•ä½¿ç”¨ç´¢å¼•
# - æŸ¥è¯¢æ—¶é—´ï¼šç§’çº§ vs æ¯«ç§’çº§
```

---

### åœºæ™¯ 3: å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†

#### PostgreSQL âœ…
```python
# models/session.py
class Message(Base):
    __tablename__ = "messages"

    id = Column(String, primary_key=True)
    session_id = Column(String)
    content = Column(Text)
    message_metadata = Column(JSONB)  # å­˜å‚¨ agent ä¿¡æ¯ã€å·¥å…·è°ƒç”¨ç­‰
    created_at = Column(DateTime)

# æŸ¥è¯¢æœ€è¿‘10æ¡å¸¦ç‰¹å®š agent çš„æ¶ˆæ¯
session.query(Message).filter(
    Message.session_id == session_id,
    Message.message_metadata['agent_name'].astext == 'summarizer'
).order_by(Message.created_at.desc()).limit(10).all()

# ç»Ÿè®¡æ¯ä¸ª agent çš„æ¶ˆæ¯æ•°
session.query(
    Message.message_metadata['agent_name'].astext.label('agent'),
    func.count().label('count')
).group_by('agent').all()
```

#### MySQL âš ï¸
```python
# æŸ¥è¯¢è¯­æ³•å¤æ‚ï¼Œæ€§èƒ½è¾ƒå·®
from sqlalchemy import func

session.query(Message).filter(
    Message.session_id == session_id,
    func.json_extract(Message.message_metadata, '$.agent_name') == 'summarizer'
).order_by(Message.created_at.desc()).limit(10).all()

# ç»Ÿè®¡æ›´å¤æ‚
session.query(
    func.json_extract(Message.message_metadata, '$.agent_name').label('agent'),
    func.count().label('count')
).group_by('agent').all()
```

---

## æ€§èƒ½åŸºå‡†æµ‹è¯•

### æµ‹è¯•åœºæ™¯: 10ä¸‡ä¸ªæ–‡æ¡£å—çš„è¯­ä¹‰æœç´¢

#### PostgreSQL + pgvector
```bash
# æŸ¥è¯¢æ—¶é—´: 15-50ms (ä½¿ç”¨ HNSW ç´¢å¼•)
# å†…å­˜ä½¿ç”¨: ~100MB
# ç´¢å¼•å¤§å°: ~500MB

SELECT text, 1 - (embedding <=> query) as similarity
FROM document_chunks
ORDER BY embedding <=> query
LIMIT 10;

Time: 23ms
```

#### MySQL (åº”ç”¨å±‚å®ç°)
```bash
# æŸ¥è¯¢æ—¶é—´: 3-10ç§’
# å†…å­˜ä½¿ç”¨: 600MB+ (å¿…é¡»åŠ è½½æ‰€æœ‰æ•°æ®)
# æ— æ³•ä½¿ç”¨ç´¢å¼•

# æ­¥éª¤:
# 1. SELECT * FROM document_chunks;  -- 2ç§’
# 2. åœ¨ Python ä¸­è®¡ç®—ç›¸ä¼¼åº¦        -- 1ç§’
# 3. æ’åºå’Œè¿”å›                   -- 0.5ç§’

Total Time: 3.5s (æ¯” PostgreSQL æ…¢ 150x)
```

---

## æœ€ç»ˆæ¨è

### âœ… æ¨èä½¿ç”¨ PostgreSQL

**ç†ç”±ï¼š**

1. **å‘é‡æœç´¢** - pgvector æ˜¯ AI åº”ç”¨çš„æ ‡é…
   - åŸç”Ÿæ”¯æŒ
   - æ€§èƒ½ä¼˜å¼‚ï¼ˆHNSW ç´¢å¼•ï¼‰
   - è¡Œä¸šæ ‡å‡†ï¼ˆLangChain, LlamaIndex å®˜æ–¹æ¨èï¼‰

2. **JSON æ”¯æŒ** - JSONB å®Œç¾é€‚é… Agent å…ƒæ•°æ®
   - å¯ç´¢å¼•
   - æŸ¥è¯¢è¯­æ³•ç®€å•
   - æ€§èƒ½ä¼˜ç§€

3. **å…¨æ–‡æœç´¢** - æ”¯æŒä¸­è‹±æ–‡
   - å†…ç½®åˆ†è¯
   - æ’åºå’Œé«˜äº®
   - å¤šè¯­è¨€æ”¯æŒ

4. **ç”Ÿæ€ç³»ç»Ÿ** - AI/ML ç¤¾åŒºé¦–é€‰
   - LangChain é»˜è®¤ä½¿ç”¨ PostgreSQL
   - Supabase (PostgreSQL) æˆä¸º AI åº”ç”¨é¦–é€‰
   - å¤§é‡ AI å·¥å…·é›†æˆ

5. **å¯æ‰©å±•æ€§** - ä¸°å¯Œçš„æ‰©å±•
   - pgvector (å‘é‡)
   - pg_trgm (æ¨¡ç³Šæœç´¢)
   - PostGIS (åœ°ç†)
   - TimescaleDB (æ—¶åº)

### âŒ ä¸æ¨èä½¿ç”¨ MySQL

**åŸå› ï¼š**
- æ— å‘é‡æœç´¢æ”¯æŒï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰
- JSON æŸ¥è¯¢æ€§èƒ½å·®
- å…¨æ–‡æœç´¢åŠŸèƒ½å¼±
- ä¸é€‚åˆ AI åº”ç”¨åœºæ™¯

---

## ä»£ç è¿ç§»æˆæœ¬

ä» SQLite è¿ç§»åˆ° PostgreSQLï¼š

### å½“å‰ä»£ç å…¼å®¹æ€§
```python
# âœ… è¿™äº›ä»£ç ä¸éœ€è¦ä¿®æ”¹
class Document(Base):
    __tablename__ = "documents"
    id = Column(String, primary_key=True)
    title = Column(String)
    content = Column(Text)

# âš ï¸ éœ€è¦ä¿®æ”¹çš„éƒ¨åˆ†
# SQLite:
summary = Column(JSON)  # SQLite çš„ JSON

# PostgreSQL:
from sqlalchemy.dialects.postgresql import JSONB
summary = Column(JSONB)  # PostgreSQL çš„ JSONB
```

### æ·»åŠ å‘é‡æœç´¢
```python
# æ–°å¢
from pgvector.sqlalchemy import Vector

class DocumentChunk(Base):
    embedding = Column(Vector(1536))  # æ–°å­—æ®µ

# requirements.txt æ·»åŠ 
pgvector>=0.2.5
```

### è¿ç§»æ­¥éª¤
1. å¯åŠ¨ PostgreSQL (Docker Compose)
2. å®‰è£… asyncpg å’Œ pgvector
3. ä¿®æ”¹ DATABASE_URL
4. è¿è¡Œè¿ç§»è„šæœ¬
5. å®Œæˆï¼

---

## ç»“è®º

**å¯¹äº ReadPilot é¡¹ç›®ï¼ŒPostgreSQL æ˜¯å”¯ä¸€åˆç†çš„é€‰æ‹©ã€‚**

MySQL ç¼ºä¹å‘é‡æœç´¢è¿™ä¸€æ ¸å¿ƒåŠŸèƒ½ï¼Œä½¿å¾—å®ƒå®Œå…¨ä¸é€‚åˆè¿™ä¸ªé¡¹ç›®ã€‚
