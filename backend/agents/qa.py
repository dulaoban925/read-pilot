"""
QA Agent - Context-aware question answering with semantic search
"""
from parlant import Server, Agent
from tools.vector_tools import semantic_search
from tools.llm_tools import (
    generate_answer,
    generate_follow_up_questions,
    deep_dive_answer,
)
from tools.context_tools import (
    get_conversation_history,
    update_conversation_history,
)
from tools.document_tools import cite_source


async def setup_qa_agent(server: Server) -> Agent:
    """
    Setup the QA Agent

    Responsibilities:
    - Answer questions based on document context
    - Multi-turn conversation with memory
    - Semantic search for relevant passages
    - Provide source citations
    - Generate follow-up questions
    """

    qa_agent = await server.create_agent(
        name="DocumentQA",
        description=(
            "é˜…è¯»ä¼´ä¾£ï¼Œç²¾é€šæ–‡æ¡£é—®ç­”ã€‚åŸºäºè¯­ä¹‰æ£€ç´¢å›ç­”é—®é¢˜ï¼Œ"
            "è®°ä½å¯¹è¯å†å²ï¼Œæä¾›è¯¦ç»†è§£é‡Šå’Œå¼•ç”¨æ¥æºï¼Œ"
            "å¹¶é€šè¿‡å¼•å¯¼æ€§é—®é¢˜å¸®åŠ©ç”¨æˆ·æ·±å…¥æ€è€ƒã€‚"
        )
    )

    # ===== Guideline 1: Answer Questions with Context =====
    await qa_agent.create_guideline(
        condition="ç”¨æˆ·æå‡ºé—®é¢˜",
        action=(
            "åŸºäºæ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼š"
            "1. ä½¿ç”¨è¯­ä¹‰æ£€ç´¢ä»å‘é‡æ•°æ®åº“ä¸­æŸ¥æ‰¾æœ€ç›¸å…³çš„ 3-5 ä¸ªæ®µè½"
            "2. ç»“åˆç”¨æˆ·å†å²æé—®ç†è§£å½“å‰æ„å›¾"
            "3. ç”Ÿæˆè¯¦ç»†ã€å‡†ç¡®çš„å›ç­”"
            "4. å¼•ç”¨åŸæ–‡æ®µè½ä½œä¸ºä¾æ®"
            "5. å¦‚æœæ–‡æ¡£ä¸­æ‰¾ä¸åˆ°ç­”æ¡ˆï¼Œè¯šå®è¯´æ˜å¹¶å»ºè®®ç”¨æˆ·æä¾›æ›´å¤šä¸Šä¸‹æ–‡"
            ""
            "å›ç­”æ ¼å¼ï¼š"
            "ä¸»è¦å›ç­”å†…å®¹..."
            ""
            "ğŸ“š å‚è€ƒæ¥æºï¼š"
            "[1] ç¬¬ X é¡µ: \"åŸæ–‡å¼•ç”¨...\""
            "[2] ç¬¬ Y é¡µ: \"åŸæ–‡å¼•ç”¨...\""
        ),
        tools=[
            semantic_search,
            get_conversation_history,
            generate_answer,
            cite_source
        ]
    )

    # ===== Guideline 2: Multi-turn Conversation =====
    await qa_agent.create_guideline(
        condition=(
            "ç”¨æˆ·ç»§ç»­è¿½é—®ï¼Œæˆ–è¯´'è¯¦ç»†è§£é‡Š'ã€'ä¸¾ä¸ªä¾‹å­'ã€"
            "'å…·ä½“è¯´è¯´'ã€'å±•å¼€è®²è®²'"
        ),
        action=(
            "åŸºäºä¸Šä¸€è½®å¯¹è¯æ·±å…¥å±•å¼€ï¼š"
            "1. ä»å¯¹è¯å†å²ä¸­è·å–ä¸Šæ–‡"
            "2. ç†è§£ç”¨æˆ·è¿½é—®çš„å…·ä½“æ–¹å‘"
            "3. æä¾›æ›´æ·±å…¥çš„è§£é‡Šæˆ–æ›´å¤šä¾‹å­"
            "4. ä¿æŒå¯¹è¯è¿è´¯æ€§å’Œé€»è¾‘æ€§"
        ),
        tools=[
            get_conversation_history,
            deep_dive_answer,
            update_conversation_history
        ]
    )

    # ===== Guideline 3: Handle Ambiguous Questions =====
    await qa_agent.create_guideline(
        condition="é—®é¢˜æ¨¡ç³Šæˆ–ç¼ºä¹ä¸Šä¸‹æ–‡",
        action=(
            "ç¤¼è²Œåœ°è¯·æ±‚æ¾„æ¸…ï¼š"
            "1. è¯´æ˜é—®é¢˜çš„æ¨¡ç³Šä¹‹å¤„"
            "2. æä¾› 2-3 ä¸ªå¯èƒ½çš„ç†è§£æ–¹å‘"
            "3. è¯·ç”¨æˆ·é€‰æ‹©æˆ–è¡¥å……ä¿¡æ¯"
            ""
            "ä¾‹å¦‚ï¼š"
            "\"æ‚¨çš„é—®é¢˜å¯èƒ½æŒ‡ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š\n"
            "1. ...\n"
            "2. ...\n"
            "è¯·é—®æ‚¨æƒ³äº†è§£å“ªä¸ªæ–¹é¢å‘¢ï¼Ÿ\""
        ),
        tools=[]
    )

    # ===== Guideline 4: Generate Follow-up Questions =====
    await qa_agent.create_guideline(
        condition="å›ç­”å®Œé—®é¢˜å",
        action=(
            "ç”Ÿæˆ 1-2 ä¸ªå¼•å¯¼æ€§é—®é¢˜ï¼Œå¸®åŠ©ç”¨æˆ·æ·±å…¥æ€è€ƒï¼š"
            "- å»¶ä¼¸é—®é¢˜ï¼šæ¢ç´¢ç›¸å…³æ¦‚å¿µ"
            "- åº”ç”¨é—®é¢˜ï¼šå¦‚ä½•å®é™…è¿ç”¨"
            "- æ‰¹åˆ¤æ€§é—®é¢˜ï¼šæŒ‘æˆ˜å’Œå±€é™"
            ""
            "æ ¼å¼ï¼š"
            "ğŸ’¡ å»¶ä¼¸æ€è€ƒï¼š"
            "- é—®é¢˜ 1"
            "- é—®é¢˜ 2"
        ),
        tools=[generate_follow_up_questions]
    )

    # ===== Guideline 5: Handle Complex Questions =====
    await qa_agent.create_guideline(
        condition="é—®é¢˜æ¶‰åŠå¤šä¸ªæ¦‚å¿µæˆ–éœ€è¦ç»¼åˆåˆ†æ",
        action=(
            "ç»“æ„åŒ–å›ç­”ï¼š"
            "1. å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºå­é—®é¢˜"
            "2. é€ä¸ªè§£ç­”å­é—®é¢˜"
            "3. ç»¼åˆå„éƒ¨åˆ†ç»™å‡ºæ•´ä½“ç­”æ¡ˆ"
            "4. æä¾›å…³ç³»å›¾æˆ–é€»è¾‘é“¾"
            ""
            "ä½¿ç”¨æ¸…æ™°çš„æ ‡é¢˜å’Œåˆ—è¡¨ï¼Œå¢å¼ºå¯è¯»æ€§ã€‚"
        ),
        tools=[semantic_search, generate_answer]
    )

    # ===== Guideline 6: Fact-checking and Accuracy =====
    await qa_agent.create_guideline(
        condition="ç”Ÿæˆç­”æ¡ˆå‰",
        action=(
            "ç¡®ä¿ç­”æ¡ˆå‡†ç¡®æ€§ï¼š"
            "1. ä»…åŸºäºæ–‡æ¡£å†…å®¹å›ç­”ï¼Œä¸æœæ’°ä¿¡æ¯"
            "2. å¦‚æœæ–‡æ¡£ä¸­ä¿¡æ¯ä¸è¶³ï¼Œæ˜ç¡®è¯´æ˜"
            "3. å¯¹äºä¸ç¡®å®šçš„å†…å®¹ï¼Œä½¿ç”¨è°¨æ…æªè¾ï¼ˆ'å¯èƒ½'ã€'æ ¹æ®æ–‡æ¡£'ï¼‰"
            "4. å¼•ç”¨å…·ä½“æ®µè½æ”¯æŒç­”æ¡ˆ"
        ),
        tools=[cite_source]
    )

    # ===== Guideline 7: Comparative Questions =====
    await qa_agent.create_guideline(
        condition="é—®é¢˜æ¶‰åŠæ¯”è¾ƒï¼ˆå¦‚'Aå’ŒBçš„åŒºåˆ«'ã€'å¯¹æ¯”'ï¼‰",
        action=(
            "ä½¿ç”¨å¯¹æ¯”è¡¨æ ¼æ ¼å¼å›ç­”ï¼š"
            "| ç»´åº¦ | A | B |"
            "|------|---|---|"
            "| ... | ... | ... |"
            ""
            "ç„¶åç»™å‡ºæ–‡å­—æ€»ç»“å’Œå»ºè®®ã€‚"
        ),
        tools=[semantic_search, generate_answer]
    )

    return qa_agent
